"""
This is an upgraded version of Ceshine's LGBM starter script, simply adding more
average features and weekly average features on it.
"""


from datetime import date, timedelta
import time
import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error
import lightgbm as lgb

camino = './input/' #google drive
camino = '/Users/gabrielkreplak/Documents/Gabi/UOC/Materiales/E4 Big Data y Sistemas NoSQL/B2.342 Trabajo Final de Master MIB-AD/Favorita/input/'

start_time = time.time()
df_train = pd.read_csv(
    camino + 'train.csv', usecols=[1, 2, 3, 4, 5],
    dtype={'onpromotion': bool},
    converters={'unit_sales': lambda u: np.log1p(float(u)) if float(u) > 0 else 0},
    parse_dates=["date"],
    skiprows=range(1, 66458909)  # 2016-01-01
)

df_stores = pd.read_csv(
    camino + "stores.csv", usecols=[0, 3, 4]
)

df_merge = df_train.merge(df_stores, on="store_nbr")

items = pd.read_csv(
    camino + "items.csv",
).set_index("item_nbr")

df_2017 = df_train.loc[df_train.date>=pd.datetime(2017,1,1)]
df_2016 = df_train.loc[df_train.date < pd.datetime(2017,1,1)]  # GK
del df_train

df_test = pd.read_csv(
    camino + "test.csv", usecols=[0, 1, 2, 3, 4],
    dtype={'onpromotion': bool},
    parse_dates=["date"]  # , date_parser=parser
).set_index(['store_nbr', 'item_nbr', 'date'])

promo_2017_train = df_2017.set_index(["store_nbr", "item_nbr", "date"])[["onpromotion"]].unstack(level=-1).fillna(False)
promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)

promo_2017_test = df_test[["onpromotion"]].unstack(level=-1).fillna(False)
promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)
promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)
promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1) #table depicting whether train & test store/item are on promotion: 167515 store/item x 243 day

del promo_2017_test, promo_2017_train

df_2017 = df_2017.set_index(
    ["store_nbr", "item_nbr", "date"])[["unit_sales"]].unstack(
        level=-1).fillna(0)
df_2017.columns = df_2017.columns.get_level_values(1) #table depicting train unit_sales for 167515 store/item x 227 day

items = items.reindex(df_2017.index.get_level_values(1)) #table depicting family, class & perishable of df_2017 existing store/items

df_merge = df_2017.merge(df_stores, on="store_nbr")


def get_timespan(df, dt, minus, periods, freq='D'):
    # get unit_sales of all 167515 store/item during certain time span

    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]

def prepare_dataset(t2017, is_train=True):
    X = pd.DataFrame({
        "day_1_2017": get_timespan(df_2017, t2017, 1, 1).values.ravel(),               # unit_sales         during                 31/5/2017 for each of all 167515 store/item
        "mean_3_2017": get_timespan(df_2017, t2017, 3, 3).mean(axis=1).values,         # unit_sales average during   3 days before 31/5/2017 for each of all 167515 store/item
        "mean_7_2017": get_timespan(df_2017, t2017, 7, 7).mean(axis=1).values,         # unit_sales average during   7 days before 31/5/2017 for each of all 167515 store/item
        "mean_14_2017": get_timespan(df_2017, t2017, 14, 14).mean(axis=1).values,      # unit_sales average during  14 days before 31/5/2017 for each of all 167515 store/item
        "mean_30_2017": get_timespan(df_2017, t2017, 30, 30).mean(axis=1).values,      # unit_sales average during  30 days before 31/5/2017 for each of all 167515 store/item
        "mean_60_2017": get_timespan(df_2017, t2017, 60, 60).mean(axis=1).values,      # unit_sales average during  60 days before 31/5/2017 for each of all 167515 store/item
        "mean_140_2017": get_timespan(df_2017, t2017, 140, 140).mean(axis=1).values,   # unit_sales average during 140 days before 31/5/2017 for each of all 167515 store/item
        "promo_14_2017": get_timespan(promo_2017, t2017, 14, 14).sum(axis=1).values,   # promo status sum   during  14 days before 31/5/2017 for each of all 167515 store/item
        "promo_60_2017": get_timespan(promo_2017, t2017, 60, 60).sum(axis=1).values,   # promo status sum   during  60 days before 31/5/2017 for each of all 167515 store/item
        "promo_140_2017": get_timespan(promo_2017, t2017, 140, 140).sum(axis=1).values # promo status sum   during 140 days before 31/5/2017 for each of all 167515 store/item
    })
    for i in range(7):
        X['mean_4_dow{}_2017'.format(i)]  = get_timespan(df_2017, t2017, 28-i, 4, freq='7D').mean(axis=1).values   # unit_sales average for each weekday during  4 weeks before 30/5/2017 for each of all 167515 store/item
        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 140-i, 20, freq='7D').mean(axis=1).values # unit_sales average for each weekday during 20 weeks before 30/5/2017 for each of all 167515 store/item
    for i in range(16):
        X["promo_{}".format(i)] = promo_2017[t2017 + timedelta(days=i)].values.astype(np.uint8) # promo status of all 167515 store/item for each of the 16 days after 30-5-17

    if is_train:
        y = df_2017[
            pd.date_range(t2017, periods=16) # unit_sales for 16 days after 31-5-17 for each of all 167515 store/item
        ].values
        return X, y
    return X

t = (time.time() - start_time)/60
print ("Time %s min" % t)

print("Preparing dataset...")
t2017 = date(2017,6,21) #(2017,6,22)0.520, (2017,6,26)0.518, (2017,6,21)0.513, (2017, 5, 31)0.515
X_l, y_l = [], []

for i in range(6): # Build training dataset 40 columns x (167 store/item x 6 weeks)
# NUEVO: range(4)
    delta = timedelta(days=7 * i)
    X_tmp, y_tmp = prepare_dataset(t2017 + delta)
    X_l.append(X_tmp)
    y_l.append(y_tmp)
X_train = pd.concat(X_l, axis=0)
y_train = np.concatenate(y_l, axis=0)
del X_l, y_l

X_val, y_val = prepare_dataset(date(2017, 7, 26)) # build validation dataset
X_test = prepare_dataset(date(2017, 8, 16), is_train=False) # build test dataset


X_train                          .to_csv(camino + 'temp/X_train.csv', float_format='%.6f', index=None)
X_val                            .to_csv(camino + 'temp/X_val.csv',   float_format='%.6f', index=None)
X_test                           .to_csv(camino + 'temp/X_test.csv',  float_format='%.6f', index=None)

pd.DataFrame(y_train)            .to_csv(camino + 'temp/y_train.csv', float_format='%.6f', index=None)
pd.DataFrame(y_val)              .to_csv(camino + 'temp/y_val.csv',   float_format='%.6f', index=None)
pd.DataFrame(index=df_2017.index).to_csv(camino + 'temp/stores_items.csv')


t = (time.time() - start_time)/60
print ("Total processing time %s min" % t)
